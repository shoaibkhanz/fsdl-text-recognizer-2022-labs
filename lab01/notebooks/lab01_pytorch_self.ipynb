{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "import requests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "filename = \"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
    "path = data_path / \"downloaded\"/\"vector_mnist\"\n",
    "path.mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (path/filename).exists():\n",
    "    content = requests.get(url+filename).content\n",
    "    (path/filename).open(\"wb\").write(content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   └── \u001b[01;34mdownloaded\u001b[0m\n",
      "│       ├── \u001b[01;34mvector-mnist\u001b[0m\n",
      "│       │   └── \u001b[01;31mmnist.pkl.gz\u001b[0m\n",
      "│       └── \u001b[01;34mvector_mnist\u001b[0m\n",
      "│           └── \u001b[01;31mmnist.pkl.gz\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "│   ├── \u001b[00mlab01_pytorch.ipynb\u001b[0m\n",
      "│   └── \u001b[00mlab01_pytorch_self.ipynb\u001b[0m\n",
      "└── \u001b[01;34mtext_recognizer\u001b[0m\n",
      "    ├── \u001b[00m__init__.py\u001b[0m\n",
      "    ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   ├── \u001b[00m__init__.cpython-310.pyc\u001b[0m\n",
      "    │   └── \u001b[00m__init__.cpython-38.pyc\u001b[0m\n",
      "    ├── \u001b[01;34mdata\u001b[0m\n",
      "    │   ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   │   └── \u001b[00mutil.cpython-38.pyc\u001b[0m\n",
      "    │   └── \u001b[00mutil.py\u001b[0m\n",
      "    ├── \u001b[01;34mmetadata\u001b[0m\n",
      "    │   ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   │   ├── \u001b[00mmnist.cpython-310.pyc\u001b[0m\n",
      "    │   │   ├── \u001b[00mmnist.cpython-38.pyc\u001b[0m\n",
      "    │   │   ├── \u001b[00mshared.cpython-310.pyc\u001b[0m\n",
      "    │   │   └── \u001b[00mshared.cpython-38.pyc\u001b[0m\n",
      "    │   ├── \u001b[00mmnist.py\u001b[0m\n",
      "    │   └── \u001b[00mshared.py\u001b[0m\n",
      "    ├── \u001b[01;34mmodels\u001b[0m\n",
      "    │   ├── \u001b[00m__init__.py\u001b[0m\n",
      "    │   ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   │   ├── \u001b[00m__init__.cpython-38.pyc\u001b[0m\n",
      "    │   │   └── \u001b[00mmlp.cpython-38.pyc\u001b[0m\n",
      "    │   └── \u001b[00mmlp.py\u001b[0m\n",
      "    └── \u001b[00mutil.py\u001b[0m\n",
      "\n",
      "13 directories, 20 files\n"
     ]
    }
   ],
   "source": [
    "!cd ../ && tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = (path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(datafile,\"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f,encoding=\"latin-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(\n",
    "    torch.tensor, (x_train, y_train, x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0,::2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-execute this cell for more samples\n",
    "import sys\n",
    "sys.path.append(\"/Users/convergeml/engineering/fsdl-text-recognizer-2022-labs/lab01\")\n",
    "\n",
    "import random\n",
    "import wandb  # just for some convenience methods that convert tensors to human-friendly datatypes\n",
    "import text_recognizer.metadata.mnist as metadata # metadata module holds metadata separate from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABLUlEQVR4nO2SIY+DQBCFZzen0GBXL5YfUFsku5Yf0aSymt8DkqQWWUtIUWiSVrGpYnZObFLR3F2h3eRMn5758ubNA/jo31UUBSJqrb0R4zhGxHmeT6eTN+hms7HWIqK1NkmS38a+VkGllERERFVVnc9nP1AAYIwBwPF4vN1ua3d/Vl3XLtMwDP0Q0zR1aSLi35Mrzs+yjIgAoCzLF309NDGKoq7rENEYo5R6Efqge5pLGrr0/DAM3d+bpnnL3V1xHE/ThIht2y75O18CzfM8CALGWNM0l8vlbZMAAODSRMTdbueHqLV23TTGSCk9EKMoGobBOT0cDgu3nmQqhBBCcM4ZY9fr1Q9UKUVE1loiyrLMD9TVk3Pe9/1+v18IfaLtdjvP8ziOQgg/xI9e0zdWGZ9npcJWgQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(x_train))\n",
    "example = x_train[idx]\n",
    "\n",
    "print(y_train[idx])  # the label of the image\n",
    "wandb.Image(example.reshape(*metadata.DIMS)).image  # the image itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x - torch.log(torch.sum(torch.exp(x), axis=1))[:, None]\n",
    "\n",
    "def model(xb: torch.Tensor) -> torch.Tensor:\n",
    "    return log_softmax(linear(xb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#64*784 , 784 * 10\n",
    "#64 * 10, 10\n",
    "#64 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.0293, -2.3486, -2.8051, -2.6019, -2.2160, -2.0180, -2.9038, -2.6996,\n",
      "        -2.2800, -1.7594], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs = 64  # batch size\n",
    "\n",
    "xb = x_train[0:bs]  # a batch of inputs\n",
    "outs = model(xb)  # outputs on that batch\n",
    "\n",
    "print(outs[0], outs.shape)  # outputs on the first element of the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1094)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "\n",
    "acc = accuracy(outs, yb)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element 0 of tensors does not require grad and does not have a grad_fn\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    acc.backward()\n",
    "except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    return -output[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(outs),type(yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3546, grad_fn=<NegBackward0>) tensor(2.3026)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    loss_func(outs, yb), \n",
    "-torch.log(torch.tensor(1 / 10))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(outs, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0180, -0.0228,  0.0265, -0.0286, -0.0283,  0.0598, -0.0227,  0.0160,\n",
       "         0.0221, -0.0400])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: tensor(2.3546, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.6536, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.8955, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.3255, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.2411, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9473, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8276, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.0709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9315, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.1125, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9486, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8854, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7753, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9009, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.0211, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7140, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.0250, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9668, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5213, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6565, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6628, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.0339, grad_fn=<NegBackward0>)\n",
      "happy: tensor(1.0436, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9132, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5016, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5510, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4201, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5320, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5960, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4910, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4775, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5173, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4433, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3270, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5016, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4492, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3880, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6113, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4749, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3360, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3995, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5995, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6166, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5240, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3440, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4901, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4117, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6194, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4140, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3493, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4206, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4597, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4120, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4506, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4192, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4862, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2858, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5039, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5397, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4816, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3158, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3650, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4534, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5628, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4965, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4325, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4521, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4408, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3957, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3713, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3622, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2159, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4552, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4495, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5059, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4867, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5460, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3909, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4248, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7584, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2853, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4723, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3932, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3101, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2389, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4944, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3860, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3524, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4067, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2959, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4733, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3657, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3339, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2352, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3955, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3312, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3475, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2861, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2651, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3040, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5250, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2550, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3210, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3198, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2701, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5061, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4552, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5982, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6817, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2942, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4363, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5104, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6459, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5739, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3018, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3278, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4324, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2511, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4917, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3567, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4115, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5407, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5182, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3852, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3304, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5238, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2446, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6897, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4541, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2548, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4412, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5071, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2973, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3314, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7056, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8081, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5679, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7270, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5253, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3238, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2088, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4883, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2486, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5043, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4192, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4739, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6051, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3085, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3839, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2711, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2012, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5777, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2121, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2474, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3335, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4119, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2558, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2548, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4424, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3787, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2270, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2330, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3067, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1544, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1855, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3128, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4333, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3706, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2842, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2938, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3072, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2670, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3033, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1989, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4484, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2020, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2865, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2593, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3179, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6305, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5088, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5685, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4464, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2792, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4015, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2737, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2720, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3921, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2700, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4707, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3836, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3742, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4422, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4127, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4615, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6833, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7518, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5898, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4466, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2940, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3001, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5794, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6406, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5863, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4911, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3303, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3434, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3878, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3292, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2361, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4320, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1627, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5470, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5205, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2730, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4077, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4554, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6441, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5218, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4641, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4390, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4191, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5527, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7164, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3721, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3710, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4883, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5058, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5133, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5971, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6780, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3353, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2448, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2560, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2593, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5937, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3744, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3641, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2702, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2675, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2950, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4040, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3234, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2633, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4385, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4347, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3724, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3637, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6721, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2046, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3406, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3293, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3187, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2480, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3469, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4634, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3484, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4435, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3503, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4374, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3298, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3488, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4371, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3818, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3514, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4438, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4334, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2152, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3638, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2734, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4689, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6644, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3041, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4784, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3562, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5723, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3421, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2697, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3021, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3026, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2134, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1962, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2509, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2810, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3362, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3473, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2509, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4514, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2722, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3854, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1846, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3468, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2070, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2316, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3671, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3552, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2854, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3838, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3336, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3515, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3694, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3438, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3958, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2526, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1615, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1008, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4448, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2353, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4037, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4509, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4049, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2630, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5923, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2550, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3091, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1833, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2416, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2337, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4891, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2936, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4987, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3676, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4405, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5780, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6787, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4322, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3774, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3225, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3111, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2135, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3060, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3790, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1342, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2522, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5493, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2639, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2778, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0994, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1411, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3166, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3510, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1688, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4591, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4610, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4697, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3329, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1085, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3077, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6513, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8107, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5188, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3187, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3472, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3177, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2272, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1317, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2654, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4499, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3671, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3467, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1730, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2714, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2609, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3316, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3013, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2550, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2993, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5734, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2301, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4220, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3416, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4654, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3919, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2553, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2258, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4071, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4703, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2432, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2946, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3960, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4585, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3843, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4112, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3782, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5160, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2948, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4068, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3630, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1454, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3402, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3157, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2845, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5064, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1240, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1266, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2404, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3513, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2342, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2631, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4275, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2060, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2783, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2344, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2503, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2160, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2160, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3584, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3110, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5874, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4334, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3615, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3935, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6142, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6261, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3778, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4116, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5030, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1466, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1957, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2577, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6886, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3745, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1882, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3108, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3444, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4394, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2225, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3824, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3154, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2492, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3959, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2437, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1996, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2266, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1912, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3230, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3162, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2470, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1566, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7167, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2448, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3502, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3175, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9259, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3133, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2711, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2191, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1524, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3191, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1638, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4382, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5095, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4272, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3460, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3155, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3426, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2445, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2660, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2873, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3338, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4974, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2462, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5825, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5200, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4826, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3554, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3992, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4777, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4166, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2430, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1857, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3215, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3991, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3059, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4826, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4005, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3753, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3390, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4810, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2785, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4452, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3243, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5128, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5799, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4074, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7708, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5848, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3982, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1712, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3167, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4888, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6337, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4229, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2950, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3638, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3846, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3741, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4695, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3602, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4903, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4967, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4756, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4755, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2645, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1271, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4456, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5502, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2695, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3642, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2645, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2824, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2358, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2325, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3270, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3826, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4277, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3700, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3098, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2815, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1835, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1814, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3875, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1009, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1677, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1920, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2830, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1987, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2284, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2034, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2008, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3231, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4621, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5353, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3319, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4959, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4294, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3654, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5333, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3212, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1792, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2884, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1899, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2810, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3646, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2075, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2059, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3129, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4824, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1895, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3367, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2649, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1898, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1630, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2768, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3019, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3961, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3725, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3143, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2749, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2398, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1193, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3055, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3855, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1982, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2646, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1493, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1933, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3387, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3034, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3045, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1844, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3112, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4358, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2763, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6479, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7219, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9294, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5424, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5374, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2609, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2838, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5101, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2966, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3581, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2898, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4021, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3124, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2263, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1910, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4149, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3247, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2556, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3647, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4270, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4857, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3533, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3018, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1848, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1760, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1904, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2428, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1648, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2984, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2535, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2806, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8236, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4058, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5589, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2804, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2607, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3448, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2847, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3869, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2603, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3251, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4616, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2412, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3490, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2940, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2189, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2862, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2925, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2344, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4062, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3414, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3167, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3026, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3670, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2094, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1809, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2187, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4884, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2570, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2956, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2357, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3490, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5259, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3223, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6489, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4223, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4584, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2294, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2224, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3267, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2309, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2205, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3449, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5251, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2682, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3466, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3431, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1686, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7225, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2488, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6570, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6268, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1650, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2706, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3644, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3809, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4861, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4534, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2837, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3515, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2705, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4719, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1184, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2169, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1657, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1661, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3488, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1611, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4142, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1465, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3273, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4284, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3966, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2578, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2514, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4480, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2068, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3992, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3944, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4159, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4820, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2845, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2244, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1655, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2033, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2797, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3735, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5180, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5183, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5016, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3777, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2842, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2401, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0977, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3633, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6425, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3424, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4487, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2665, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2312, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5136, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4011, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4004, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3547, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4000, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4784, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2862, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5074, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6511, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3928, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4917, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1628, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1701, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2884, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1332, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4117, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1096, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2248, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2558, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3233, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1962, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2412, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3050, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4358, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3666, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3189, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4098, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1623, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6256, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2413, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3763, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3695, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1819, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4049, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4521, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2145, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2962, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1361, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1407, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1988, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5927, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2565, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1614, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3283, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2254, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3085, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1694, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1758, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2421, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5803, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6585, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4618, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2619, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4342, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2558, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2081, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1244, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3194, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6884, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5801, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5741, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2893, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2212, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3388, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6325, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2317, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4103, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2771, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4650, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3200, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3742, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1357, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2012, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4708, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2173, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4296, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3497, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2123, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3122, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5525, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3970, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2841, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6436, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0899, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5508, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3677, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6926, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2408, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2984, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3455, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1904, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2338, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2117, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2765, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1138, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2127, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2684, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3283, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1674, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3154, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1413, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1613, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3373, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1405, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1161, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1949, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4252, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2666, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3498, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2230, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2183, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2490, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4053, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2410, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1520, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3349, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3004, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2143, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2510, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2555, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1175, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4983, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4137, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3599, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1322, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1209, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2935, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4248, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4048, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3529, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3203, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2148, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2387, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2103, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2583, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1145, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3673, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2124, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3133, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2986, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4970, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2834, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2524, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6278, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2118, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3545, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2561, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2318, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0986, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3728, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2535, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3074, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2938, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2125, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3540, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2797, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2408, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1519, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3371, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1299, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1966, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1361, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1505, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2551, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3827, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1671, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2066, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2086, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1623, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3836, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4219, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4723, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5720, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2146, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3415, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3763, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4239, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4445, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1878, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2036, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3157, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2138, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3119, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2499, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2662, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4861, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3972, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2445, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2144, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4145, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1736, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5788, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3305, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1640, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3058, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5349, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2547, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2592, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5452, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7825, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5156, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5472, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3992, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2421, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1466, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4301, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2355, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3935, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3221, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3487, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5096, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2577, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3684, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1986, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0906, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4377, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1099, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1708, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2579, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3448, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1855, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2209, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5084, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2354, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2182, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1455, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2070, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0961, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1255, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2160, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4025, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2795, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2428, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2165, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2680, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2404, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1654, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1312, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3289, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1548, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2035, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2372, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2731, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5570, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4237, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5546, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4473, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1904, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3290, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2089, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2150, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3260, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2143, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4747, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2601, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2997, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3524, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3111, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3952, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6385, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6486, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5115, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3411, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1933, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2487, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5237, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5761, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4711, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3935, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2431, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2868, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2651, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1936, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3785, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1205, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4495, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4190, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2074, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3708, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2963, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6107, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4894, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3871, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3434, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3340, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4028, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7630, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3123, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2665, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3943, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4139, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4279, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5846, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6682, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2620, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2187, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2169, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2281, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5577, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3098, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2686, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2285, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1808, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2482, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3052, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2492, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1989, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3396, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3625, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2853, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2295, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6149, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4854, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2121, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1543, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2346, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2698, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2857, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1833, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2998, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4561, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3054, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3592, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2566, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3657, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2584, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2713, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3598, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3370, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2868, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3941, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1459, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2998, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2296, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3939, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5279, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2285, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3674, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3020, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4675, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2584, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2567, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2810, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1602, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1383, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2469, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2714, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3157, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2474, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4102, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1966, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3660, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1375, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3227, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1568, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1795, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3222, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3032, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2164, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3411, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2765, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2983, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3168, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3422, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2241, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1357, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0928, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4285, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1613, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2807, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3278, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3266, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1943, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5245, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2019, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2618, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1593, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1960, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1932, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4067, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2764, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5131, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3559, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3891, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6108, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6914, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4051, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3674, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2928, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2892, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1589, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2844, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3001, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0896, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2082, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5198, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2563, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2405, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0846, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1014, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2737, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3479, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1077, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3615, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4067, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4755, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2872, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0749, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2592, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5231, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6725, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4489, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2512, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2598, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2575, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2162, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0920, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2599, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4324, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3307, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3194, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1205, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2019, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2244, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3251, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2263, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2477, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2382, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5250, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1718, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3653, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2952, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4609, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3373, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2125, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1913, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3143, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4138, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1983, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2360, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3177, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4210, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3378, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3880, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2991, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4610, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2633, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3562, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2947, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1037, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3053, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2821, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2285, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4732, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0967, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0951, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2354, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3255, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2096, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2329, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2277, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4173, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1663, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2277, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1993, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2341, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1702, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1734, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3132, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2860, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5772, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3372, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3749, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3493, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5750, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3730, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3688, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4819, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1129, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1681, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2153, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7235, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3958, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1612, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2768, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2885, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3869, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2222, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3365, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3117, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2080, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3416, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2388, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1517, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1847, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1520, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2819, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2549, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2150, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1109, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7183, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1936, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3372, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3229, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8338, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2559, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2190, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1786, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1222, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2939, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1334, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3341, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4145, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3844, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2936, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2597, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3026, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1938, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2392, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2542, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2769, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4295, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2068, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5173, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4355, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4284, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3066, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3621, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4077, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3716, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2161, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1612, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3428, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2623, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4315, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3310, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3457, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2880, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4268, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2509, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4002, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3242, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5073, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5608, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3475, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.7222, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5359, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3765, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1412, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2904, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4260, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6002, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3680, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2782, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2730, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3397, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3568, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3268, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4356, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3122, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4484, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4459, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4368, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3954, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2074, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1023, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4519, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2609, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5248, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2539, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3600, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2180, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2537, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1992, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1874, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2791, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3995, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3699, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3315, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2804, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2583, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1596, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1593, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3482, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1113, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0860, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1488, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1740, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2553, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1688, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1925, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1796, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1663, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3114, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4115, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5015, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2927, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4483, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3714, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3488, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4854, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2772, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1626, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2895, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1689, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2526, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3251, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1754, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1878, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2813, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4711, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1683, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3029, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2182, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1638, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1324, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2426, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2685, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3162, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3632, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2771, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2481, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2418, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0978, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2843, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3761, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1736, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2504, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1327, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1779, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3227, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2741, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2706, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1549, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2800, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4326, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4434, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2392, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6004, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6924, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.9241, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5467, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4878, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2172, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2765, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5021, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2675, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3382, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2714, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4025, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2758, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1890, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1521, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3817, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3116, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3366, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2208, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3406, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3869, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4593, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3330, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2809, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1500, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1475, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1792, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2046, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1511, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2777, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2312, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2607, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.8100, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4009, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5237, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2567, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2225, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3167, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2525, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3286, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2170, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2671, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4345, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2083, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3503, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2681, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1697, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2747, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2859, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2005, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3721, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3147, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2749, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2714, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3654, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1765, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1804, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2050, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4853, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2487, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2759, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2327, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3378, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5059, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3051, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6269, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3835, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4043, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1986, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1919, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2785, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2082, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1907, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3251, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5078, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2380, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3221, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3113, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1468, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2544, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6704, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6257, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1515, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2432, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3464, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3552, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3883, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4341, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4102, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2595, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3120, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2758, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4508, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0905, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2193, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1374, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1380, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3473, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1292, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1210, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2735, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3954, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3742, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2539, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1976, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4143, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1697, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3543, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3779, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3709, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4744, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2477, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1982, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1614, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1875, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2376, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3587, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5105, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3182, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4989, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4590, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3552, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2565, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2045, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0804, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3299, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6053, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3080, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4486, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2408, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2046, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5045, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3689, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3684, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3210, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3571, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4480, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2547, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5051, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6262, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3737, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4665, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1344, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1477, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2609, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1138, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4241, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.0925, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2160, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2370, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2912, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1790, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2168, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2795, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4217, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3098, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2776, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4079, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1396, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6175, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2067, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3673, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3202, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1727, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3812, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4410, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1881, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2746, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1092, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1151, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1832, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5916, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2159, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1514, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2865, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1997, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2920, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1591, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1634, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2186, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5672, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6561, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.4216, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2188, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3915, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2456, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2015, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.1085, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2816, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6608, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5587, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.5495, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2612, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2053, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3134, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.6335, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.2046, grad_fn=<NegBackward0>)\n",
      "happy: tensor(0.3179, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.5\n",
    "epochs = 2\n",
    "n, c = x_train.shape\n",
    "\n",
    "for e in range(epochs):\n",
    "     for ii in range((n - 1) // bs + 1):  # in batches of size bs, so roughly n / bs of them\n",
    "        start_idx = ii * bs  # we are ii batches in, each of size bs\n",
    "        end_idx = start_idx + bs  # and we want the next bs entires\n",
    "\n",
    "        # pull batches from x and from y\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "\n",
    "        # run model\n",
    "        pred = model(xb)\n",
    "\n",
    "        # get loss\n",
    "        loss = loss_func(pred, yb)\n",
    "        print(\"happy:\",loss)\n",
    "        # calculate the gradients with a backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad*lr\n",
    "            bias -= bias.grad*lr\n",
    "\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0829, grad_fn=<NegBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABz0lEQVR4nO2SP4vqUBDFR12MFkoggQiilqKxtLMKFhYiWthYWEu+gFhZ2NiINlYWFhaiNn4IIWAnSLRRFNQmFooo/oPMKy4v7Fv3BZJd2GZPNZzD/O7MZQB+9VPieV6WZUTMZDLfBh2NRoiIiOfzud1ufwPR6/UqioJ/db/fS6XSV6Gz2QwRn89nMpnsdDqIeLlcwuGweWIsFns8HohYrVYBgGEYSZIQ8Xq9RqNRM0SapqfTKdk6n88TUxAE4pTLZTPQQCBA+lerlc1m014i5ng8pijKMLRWq5F+QRA0k6KoyWRCfJZljRF9Pt/hcEDE9XrtdrvfR4PBQAdq1YGKokjTNADkcrnT6fQ+kiSJFAzDGIBaLBae5wFAVVVZlj+k8/mcFMFgUGesj4pEImTBfr//miYSCTPrp1IpMmav13tN7Xa7zkB6fwoAm81mOBy++trNGoM6nc7/9litDocDAG63m6qq+mP9o8ViQY7pNdKOv9FofNr7ZuAdAADgOE4URQDYbrfNZtMMlOO4YrG42+0AgGXZdDodCoU8Hg8AZLPZ5XJpbKJCoXA8HvEzKYpSr9ddLpcxIlE8Hu92uxprv9+3Wq1KpeL3+83gfvUV/QHAww55alVbjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-execute this cell for more samples\n",
    "idx = random.randint(0, len(x_train))\n",
    "example = x_train[idx:idx+1]\n",
    "\n",
    "out = model(example)\n",
    "\n",
    "print(out.argmax())\n",
    "wandb.Image(example.reshape(28, 28)).image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0829, grad_fn=<NllLossBackward0>) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))  # should be unchanged from above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(784,10)/math.sqrt(784))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "    \n",
    "    # def forward(self, xb: torch.Tensor):\n",
    "    #     outs = xb @ self.weights + self.bias\n",
    "    #     return outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, xb: torch.Tensor) -> torch.Tensor:\n",
    "    return xb @ self.weights + self.bias\n",
    "\n",
    "MNISTLogistic.forward = forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1783e-02, -3.0539e-01, -4.4323e-01, -3.7763e-01,  2.1540e-01,\n",
      "         -7.2736e-02,  1.0071e-01,  6.8461e-01, -9.8071e-01, -2.0296e-01],\n",
      "        [-2.0387e-01,  5.6281e-02, -5.4158e-01,  4.6071e-01,  1.3599e-01,\n",
      "         -2.0744e-01, -9.2254e-01,  5.8820e-01, -1.2015e+00, -8.1617e-02],\n",
      "        [ 1.7568e-01, -8.8359e-02, -4.8334e-01, -3.1407e-04,  4.5750e-01,\n",
      "         -6.6327e-01, -5.4357e-01,  7.4714e-01,  2.0133e-02, -2.9589e-01],\n",
      "        [ 2.9915e-01, -6.7942e-02, -5.6946e-01,  2.1351e-01,  5.6403e-01,\n",
      "         -6.9438e-02, -5.1871e-01,  5.1175e-01, -7.6848e-01,  6.7242e-02]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 7.9008e-03,  6.7557e-03,  6.5431e-03,  3.3513e-03,  4.2531e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.4723e-02, -1.8566e-02,  5.6474e-02,  2.5747e-02, -1.5486e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.6956e-02,  1.4719e-02, -4.0960e-02,  1.5512e-02, -4.7790e-02],\n",
      "        [ 2.7043e-02,  2.0967e-02,  1.7841e-02,  1.2204e-02, -5.4735e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-6.5802e-02,  1.1449e-02,  5.2702e-02,  2.8205e-02, -3.9869e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.2835e-02,  2.1292e-02,  2.2292e-03,  1.9727e-02, -2.1981e-02],\n",
      "        [-5.0583e-02,  4.9642e-02,  5.2751e-02,  4.1060e-02, -1.3083e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 2.6926e-02,  2.1776e-02,  2.7425e-02,  1.2677e-02, -5.5539e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.8705e-02,  5.8802e-03,  3.4139e-03,  6.1328e-03,  3.5198e-03],\n",
      "        [ 2.9163e-02,  1.6497e-02, -5.4804e-02,  1.6129e-02, -4.5618e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 5.4965e-02,  3.3340e-02, -1.2296e-02,  2.9891e-02, -8.5366e-02],\n",
      "        [ 8.5714e-03,  4.4896e-03, -5.3979e-02,  8.2767e-03,  3.7080e-03],\n",
      "        [-2.8790e-02,  3.4341e-03,  2.0431e-03,  3.6576e-03,  2.3005e-03],\n",
      "        [-8.9543e-03, -2.9446e-02, -3.8238e-02,  3.3793e-02, -1.7728e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-1.0453e-02, -2.1151e-02, -2.8795e-02,  3.9030e-02, -1.0942e-01],\n",
      "        [-5.2430e-02,  8.3685e-03,  5.9995e-03,  6.3884e-03,  5.4377e-03],\n",
      "        [-1.2820e-03,  1.5964e-04,  1.1025e-04,  1.3141e-04,  1.0380e-04],\n",
      "        [-4.3274e-02,  3.3101e-02,  3.8961e-04,  2.2174e-02, -1.2522e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-7.7664e-02,  2.7262e-02, -5.2789e-03,  4.0938e-02, -9.0492e-02],\n",
      "        [-5.2507e-02,  8.3249e-03,  5.8895e-03,  6.2851e-03,  5.4137e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-9.4411e-02,  3.1501e-03,  8.4139e-02,  4.9214e-02, -1.2941e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.7360e-02,  1.2976e-02,  1.5816e-02,  1.1769e-02, -4.9619e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 9.5051e-04,  5.4338e-04,  1.0720e-03,  5.9511e-04,  8.7771e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()  # instantiated as an object\n",
    "print(model(xb)[:4])  # callable like a function\n",
    "loss = loss_func(model(xb), yb)  # composable like a function\n",
    "loss.backward()  # we can still take gradients through it\n",
    "print(model.weights.grad[::17,::2])  # and they show up in the .grad attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0363, -0.0251,  0.0149,  ...,  0.0222, -0.0090,  0.0636],\n",
      "        [ 0.0069,  0.0207, -0.0274,  ..., -0.0096,  0.0467,  0.0107],\n",
      "        [-0.0504,  0.0296,  0.0005,  ...,  0.0076,  0.0059, -0.0065],\n",
      "        ...,\n",
      "        [-0.0152,  0.0118,  0.0279,  ...,  0.0026,  0.0050,  0.0342],\n",
      "        [-0.0167, -0.0463,  0.0168,  ..., -0.0831, -0.0235, -0.0313],\n",
      "        [ 0.0767, -0.0261,  0.0512,  ...,  0.0231,  0.0057, -0.0075]],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(*list(model.parameters()),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for e in epochs:\n",
    "        for ii in range((n-1)//bs+1):\n",
    "            start_idx = ii * bs\n",
    "            end_idx = start_idx+bs\n",
    "            xb = x_train[start_idx:end_idx]\n",
    "            yb = y_train[start_idx:end_idx]\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred,yb)\n",
    "            \n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p-= lr * p.grad\n",
    "                model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0625)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.nn.Modules:\n",
      "\tModule, Identity, Linear, Conv1d, Conv2d, Conv3d, ConvTranspose1d,\n",
      "\tConvTranspose2d, ConvTranspose3d, Threshold, ReLU, Hardtanh, ReLU6,\n",
      "\tSigmoid, Tanh, Softmax, Softmax2d, LogSoftmax, ELU, SELU, CELU, GLU,\n",
      "\tGELU, Hardshrink, LeakyReLU, LogSigmoid, Softplus, Softshrink,\n",
      "\tMultiheadAttention, PReLU, Softsign, Softmin, Tanhshrink, RReLU,\n",
      "\tL1Loss, NLLLoss, KLDivLoss, MSELoss, BCELoss, BCEWithLogitsLoss,\n",
      "\tNLLLoss2d, PoissonNLLLoss, CosineEmbeddingLoss, CTCLoss,\n",
      "\tHingeEmbeddingLoss, MarginRankingLoss, MultiLabelMarginLoss,\n",
      "\tMultiLabelSoftMarginLoss, MultiMarginLoss, SmoothL1Loss,\n",
      "\tGaussianNLLLoss, HuberLoss, SoftMarginLoss, CrossEntropyLoss,\n",
      "\tContainer, Sequential, ModuleList, ModuleDict, ParameterList,\n",
      "\tParameterDict, AvgPool1d, AvgPool2d, AvgPool3d, MaxPool1d, MaxPool2d,\n",
      "\tMaxPool3d, MaxUnpool1d, MaxUnpool2d, MaxUnpool3d, FractionalMaxPool2d,\n",
      "\tFractionalMaxPool3d, LPPool1d, LPPool2d, LocalResponseNorm,\n",
      "\tBatchNorm1d, BatchNorm2d, BatchNorm3d, InstanceNorm1d, InstanceNorm2d,\n",
      "\tInstanceNorm3d, LayerNorm, GroupNorm, SyncBatchNorm, Dropout,\n",
      "\tDropout1d, Dropout2d, Dropout3d, AlphaDropout, FeatureAlphaDropout,\n",
      "\tReflectionPad1d, ReflectionPad2d, ReflectionPad3d, ReplicationPad2d,\n",
      "\tReplicationPad1d, ReplicationPad3d, CrossMapLRN2d, Embedding,\n",
      "\tEmbeddingBag, RNNBase, RNN, LSTM, GRU, RNNCellBase, RNNCell, LSTMCell,\n",
      "\tGRUCell, PixelShuffle, PixelUnshuffle, Upsample, UpsamplingNearest2d,\n",
      "\tUpsamplingBilinear2d, PairwiseDistance, AdaptiveMaxPool1d,\n",
      "\tAdaptiveMaxPool2d, AdaptiveMaxPool3d, AdaptiveAvgPool1d,\n",
      "\tAdaptiveAvgPool2d, AdaptiveAvgPool3d, TripletMarginLoss, ZeroPad2d,\n",
      "\tConstantPad1d, ConstantPad2d, ConstantPad3d, Bilinear,\n",
      "\tCosineSimilarity, Unfold, Fold, AdaptiveLogSoftmaxWithLoss,\n",
      "\tTransformerEncoder, TransformerDecoder, TransformerEncoderLayer,\n",
      "\tTransformerDecoderLayer, Transformer, LazyLinear, LazyConv1d,\n",
      "\tLazyConv2d, LazyConv3d, LazyConvTranspose1d, LazyConvTranspose2d,\n",
      "\tLazyConvTranspose3d, LazyBatchNorm1d, LazyBatchNorm2d,\n",
      "\tLazyBatchNorm3d, LazyInstanceNorm1d, LazyInstanceNorm2d,\n",
      "\tLazyInstanceNorm3d, Flatten, Unflatten, Hardsigmoid, Hardswish, SiLU,\n",
      "\tMish, TripletMarginWithDistanceLoss, ChannelShuffle\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print(\"torch.nn.Modules:\", *textwrap.wrap(\", \".join(torch.nn.modules.__all__)), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(784,10)\n",
    "    \n",
    "    def forward(self,xb:torch.Tensor):\n",
    "        return self.lin(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3291, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "print(loss_func(model(xb), yb))  # loss is still close to 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Linear(in_features=784, out_features=10, bias=True)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0226, -0.0180, -0.0316,  ...,  0.0177,  0.0009, -0.0053],\n",
       "         [-0.0242,  0.0321,  0.0076,  ..., -0.0009, -0.0154,  0.0353],\n",
       "         [-0.0336, -0.0246, -0.0280,  ..., -0.0067,  0.0250, -0.0034],\n",
       "         ...,\n",
       "         [ 0.0276, -0.0107, -0.0072,  ..., -0.0260, -0.0260, -0.0320],\n",
       "         [-0.0224,  0.0280,  0.0223,  ...,  0.0351,  0.0129, -0.0117],\n",
       "         [ 0.0040, -0.0044,  0.0248,  ...,  0.0307,  0.0256,  0.0175]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0037,  0.0038, -0.0177,  0.0186, -0.0013, -0.0273,  0.0199, -0.0218,\n",
       "         -0.0265,  0.0299], requires_grad=True)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "def configure_optimiser(model: nn.Module) -> optim.Optimizer:\n",
    "    return optim.Adam(model.parameters(),lr=3e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTLogistic()\n",
    "opt = configure_optimiser(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training:\n",
      "\ttensor(2.2273, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"before training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training:\n",
      "\ttensor(0.4769, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    for ii in range((n-1)//bs+1):\n",
    "        start_idx = ii*bs\n",
    "        end_idx = start_idx + bs\n",
    "        xb = x_train[start_idx:end_idx]\n",
    "        yb = y_train[start_idx:end_idx]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred,yb) \n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(\"after training:\", loss_func(model(xb), yb), sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.data.util import BaseDataset\n",
    "train_ds = BaseDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNISTLogistic()\n",
    "opt = configure_optimiser(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4676, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for ii in range((n - 1) // bs + 1):\n",
    "        xb, yb = train_ds[ii * bs: ii * bs + bs]  # xb and yb in one line!\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_ds = BaseDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self: nn.Module, train_dataloader: DataLoader):\n",
    "    opt = configure_optimiser(self)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for xb, yb in train_dataloader:\n",
    "            pred = self(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "MNISTLogistic.fit = fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4835, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = MNISTLogistic()\n",
    "model.fit(train_dataloader)\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Swapping in another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_recognizer.models.mlp import MLP\n",
    "MLP.fit = fit  # attach our fitting loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Defines the computation performed at every call.\n",
      "\n",
      "Should be overridden by all subclasses.\n",
      "\n",
      ".. note::\n",
      "    Although the recipe for forward pass needs to be defined within\n",
      "    this function, one should call the :class:`Module` instance afterwards\n",
      "    instead of this since the former takes care of running the\n",
      "    registered hooks while the latter silently ignores them.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/engineering/fsdl-text-recognizer-2022-labs/lab01/text_recognizer/models/mlp.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "MLP.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mMLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdata_config\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_dims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfc1_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC1_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfc2_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC2_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdropout_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fc_dropout\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFC_DROPOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc1_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc1_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfc2_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc2_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/engineering/fsdl-text-recognizer-2022-labs/lab01/text_recognizer/models/mlp.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "MLP.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_dims': (784,),\n",
       " 'mapping': {0: '0',\n",
       "  1: '1',\n",
       "  2: '2',\n",
       "  3: '3',\n",
       "  4: '4',\n",
       "  5: '5',\n",
       "  6: '6',\n",
       "  7: '7',\n",
       "  8: '8',\n",
       "  9: '9'}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits_to_9 = list(range(10))\n",
    "data_config = {\"input_dims\": (784,), \"mapping\": {digit: str(digit) for digit in digits_to_9}}\n",
    "data_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(data_config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 784])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before training tensor(2.2953, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 7.84 ms, sys: 6.07 ms, total: 13.9 ms\n",
      "Wall time: 13.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"before training\",loss_func(model(xb),yb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = BaseDataset(x_train, y_train)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)\n",
    "fit(model, train_dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after training tensor(0.0382, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"after training\",loss_func(model(xb),yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "☹️\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"☹️\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0881, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "loss_func(model(xb.to(device)), yb.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def push_to_device(tensor):\n",
    "    return tensor.to(device)\n",
    "\n",
    "train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
    "train_dataloader = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0201, grad_fn=<NllLossBackward0>)\n",
      "CPU times: user 2min 53s, sys: 6.65 s, total: 2min 59s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = MLP(data_config)\n",
    "model.to(device)\n",
    "\n",
    "model.fit(train_dataloader)\n",
    "\n",
    "print(loss_func(model(push_to_device(xb)), push_to_device(yb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule():\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "\n",
    "    def __init__(self, dir, bs=32):\n",
    "        self.dir = dir\n",
    "        self.bs = bs\n",
    "        self.path = self.dir/self.filename\n",
    "\n",
    "    def prepare_data(self):\n",
    "        if not (self.path).exists():\n",
    "            content = requests.get(self.url+self.filename).content\n",
    "            self.path.open(\"wb\").write(content)\n",
    "    \n",
    "    def setup(self):\n",
    "        with gzip.open(self.path,\"rb\") as f:\n",
    "            ((x_train,y_train),(x_valid,y_valid), _) = pickle.load(f,encoding=\"latin-1\") \n",
    "        \n",
    "        x_train,y_train,x_valid,y_valid = map(torch.tensor,x_train,y_train,x_valid,y_valid)\n",
    "        self.train_ds = BaseDataset(x_train, y_train, transform=push_to_device, target_transform=push_to_device)\n",
    "        self.valid_ds = BaseDataset(x_valid, y_valid, transform=push_to_device, target_transform=push_to_device)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_ds, batch_size=self.bs,shuffle=True)\n",
    "    \n",
    "    def valid_dataloader(self):\n",
    "        return DataLoader(self.valid_ds, batch_size=self.bs,shuffle=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "615c6171f0848c6085d9ca7f7f9eb3980c07ad2defb79dfee5e6efbdf8c7dd06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
