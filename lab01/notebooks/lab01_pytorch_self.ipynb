{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gzip\n",
    "import pickle\n",
    "import requests\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "filename = \"mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
    "path = data_path / \"downloaded\"/\"vector_mnist\"\n",
    "path.mkdir(parents=True,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (path/filename).exists():\n",
    "    content = requests.get(url+filename).content\n",
    "    (path/filename).open(\"wb\").write(content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m.\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "│   └── \u001b[01;34mdownloaded\u001b[0m\n",
      "│       └── \u001b[01;34mvector_mnist\u001b[0m\n",
      "│           └── \u001b[01;31mmnist.pkl.gz\u001b[0m\n",
      "├── \u001b[01;34mnotebooks\u001b[0m\n",
      "│   ├── \u001b[00mlab01_pytorch.ipynb\u001b[0m\n",
      "│   └── \u001b[00mlab01_pytorch_self.ipynb\u001b[0m\n",
      "└── \u001b[01;34mtext_recognizer\u001b[0m\n",
      "    ├── \u001b[00m__init__.py\u001b[0m\n",
      "    ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   ├── \u001b[00m__init__.cpython-310.pyc\u001b[0m\n",
      "    │   └── \u001b[00m__init__.cpython-38.pyc\u001b[0m\n",
      "    ├── \u001b[01;34mdata\u001b[0m\n",
      "    │   └── \u001b[00mutil.py\u001b[0m\n",
      "    ├── \u001b[01;34mmetadata\u001b[0m\n",
      "    │   ├── \u001b[01;34m__pycache__\u001b[0m\n",
      "    │   │   ├── \u001b[00mmnist.cpython-310.pyc\u001b[0m\n",
      "    │   │   ├── \u001b[00mmnist.cpython-38.pyc\u001b[0m\n",
      "    │   │   ├── \u001b[00mshared.cpython-310.pyc\u001b[0m\n",
      "    │   │   └── \u001b[00mshared.cpython-38.pyc\u001b[0m\n",
      "    │   ├── \u001b[00mmnist.py\u001b[0m\n",
      "    │   └── \u001b[00mshared.py\u001b[0m\n",
      "    ├── \u001b[01;34mmodels\u001b[0m\n",
      "    │   ├── \u001b[00m__init__.py\u001b[0m\n",
      "    │   └── \u001b[00mmlp.py\u001b[0m\n",
      "    └── \u001b[00mutil.py\u001b[0m\n",
      "\n",
      "10 directories, 16 files\n"
     ]
    }
   ],
   "source": [
    "!cd ../ && tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = (path/filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(datafile,\"rb\") as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f,encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(torch.Tensor,\n",
    "(x_train, y_train,x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([392])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0,::2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-execute this cell for more samples\n",
    "import sys\n",
    "sys.path.append(\"/Users/convergeml/engineering/fsdl-text-recognizer-2022-labs/lab01\")\n",
    "\n",
    "import random\n",
    "import wandb  # just for some convenience methods that convert tensors to human-friendly datatypes\n",
    "import text_recognizer.metadata.mnist as metadata # metadata module holds metadata separate from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAApElEQVR4nGNgGAXDBCgpKV29evX//////v2bNGmSiYkJFQwNDQ39iwQaGxsJamEi1Q4PDw8hISEqG2piYsLDw0NlQ4kBo4aOGkp3Q1++fPn27VsqG3ro0KHz589T2VAyAFGG3rp1C5nb3NxMBZvl5eWRS7/Q0FD86snx/smTJ6lg6K9fv549ewbnxsXFkeEULMDExOTDhw9///7dtGkTwfJ0hAMApuhIseZ9Ho8AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=28x28>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = random.randint(0, len(x_train))\n",
    "example = x_train[idx]\n",
    "\n",
    "print(y_train[idx])  # the label of the image\n",
    "wandb.Image(example.reshape(1,28,28)).image  # the image itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_()\n",
    "bias = torch.zeros(10,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x: torch.Tensor) -> torch.Tensor:\n",
    "    return x @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsoftmax(x: torch.Tensor):\n",
    "    return x - torch.log(torch.sum(torch.exp(x),axis=1))[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x: torch.Tensor):\n",
    "    return logsoftmax(linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#64*784 , 784 * 10\n",
    "#64 * 10, 10\n",
    "#64 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.7050, -2.3431, -2.2415, -2.3054, -2.4837, -2.8456, -2.2032, -1.7082,\n",
      "        -2.0582, -2.6560], grad_fn=<SelectBackward0>) torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "bs=64\n",
    "xb = x_train[0:bs]\n",
    "outs = model(xb)\n",
    "\n",
    "print(outs[0],outs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "615c6171f0848c6085d9ca7f7f9eb3980c07ad2defb79dfee5e6efbdf8c7dd06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
